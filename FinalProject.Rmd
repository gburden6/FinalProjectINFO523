---
title: "FinalProject KNN Algorithm"
author: "Grant Burden"
date: "2023-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Final Project for INFO 523

```{r}
'P. W. Frey and D. J. Slate (Machine Learning Vol 6 #2 March 91):
	"Letter Recognition Using Holland-style Adaptive Classifiers".'

```

```{r, echo = FALSE, results = 'hide'}
library(caret)
library(tidyverse)

```

```{r}
#Load the UCi dataset
letters1<- read.csv('./letter-recognition.data', header = FALSE)

#names is citation info--not needed for algorithm
#names1 <- read.csv('./letter-recognition.names', header = FALSE)

head(letters1)

#we have 16 predictors for 26 classes, and 20k observations total
str(letters1)
names(letters1)

#Renaame Column Headers

letters2 <- letters1%>%rename(
 letter  = V1,
  xPos = V2,
  yPos = V3,
  pixWidth = V4,
   pixHeight= V5,
  pixOn = V6,
  xMean = V7,
   yMean= V8,
  xMeanSq = V9,
   yMeanSq= V10,
   XYMean= V11,
  xCorY = V12,
  YCorX = V13,
  edgeMeanHoriz = V14,
   edgeYSum= V15,
   edgeMeanY= V16,
   edgeXSum= V17
   
) 


```
Split into test and Training sets
Trying a 70/30 train test split
set seed for the same splits

```{r}
#split into training and test
#Get indices of rows in training set, 70% of rows of letters1, 
#set seed keep split consistent

set.seed(6)
indexTrain<- createDataPartition(letters2$xPos, times =1,  p = 0.70, list = FALSE)

#define training set
trainSet <- letters2[indexTrain, ]
#define test set as complement of the test set
testSet <- letters2[-indexTrain, ]


```
Try different values for K--find optimal accuracy and plot it
sqrt(n) ~ 140

```{r}
knnFit<- train(letter ~., data = trainSet, method ='knn' , tuneGrid = data.frame( k = c(141)))

#multiKnnFit<- knnFit<- train(letter ~., data = trainSet, method ='knn' , tuneGrid = data.frame( k = seq(141, 200,2)))


#view results of knnFit model
knnFit$results

knnTestPredict<- predict(knnFit, newdata = testSet )


class(knnTestPredict)
#how accurate did knn predict the letters on the test set
confMatrixKnn<- confusionMatrix(knnTestPredict, as.factor(testSet$letter))


```


```{r}
#make the results into a df
cm_df<- as.data.frame(confMatrixKnn$byClass)

cm_df
#add column with Letter Classes
letter_col<- LETTERS[seq(from = 1 , to = 26)]
letters_df<- cm_df%>%mutate(Letter_Class = letter_col)

plot_balanced_acc<- letters_df%>%ggplot(aes(x = Letter_Class, y = `Balanced Accuracy` ))+
  geom_point(col = 'darkblue')+
  ggtitle('Balanced Accuracy for Letter Predictions via KNN')+
  xlab('Letter Class')

plot_specificity <- letters_df%>%ggplot(aes(x = Letter_Class, y = Specificity ))+
  geom_point(col = 'darkgreen')+
  ggtitle('Specificity for Letter Predictions via KNN')+
  xlab('Letter Class')


plot_sensitivity <- letters_df%>%ggplot(aes(x = Letter_Class, y = Sensitivity))+
  geom_point(col = 'maroon4')+
  ggtitle('Sensitivity for Letter Predictions via KNN')+
  xlab('Letter Class')
```


```{r}
#Model using only edge parameters with K = 141

edgeknnFit<- train(letter ~edgeMeanHoriz+edgeYSum+edgeMeanY+edgeXSum, data = trainSet, method ='knn' , tuneGrid = data.frame( k = c(141)))

# accuracy 0.5226863

edgeknnTestPredict<- predict(edgeknnFit, newdata = testSet )

confusionMatrix(edgeknnTestPredict, as.factor(testSet$letter))
```

```{r}
#Training model on mean horizontal and vertical positions, overall width, height and number of 'on' pixels

positionknnFit<- train(letter ~ xPos+
  yPos+
  pixWidth+
   pixHeight+
  pixOn+
  xMean+
   yMean, data = trainSet, method ='knn' , tuneGrid = data.frame( k = c(141)))

PositionknnTestPredict<- predict(positionknnFit, newdata = testSet )
```

```{r}

set.seed(6)
indexTrainEighty<- createDataPartition(letters2$xPos, times =1,  p = 0.80, list = FALSE)

#define training set
trainSetEighty <- letters2[indexTrainEighty, ]
#define test set as complement of the test set
testSetEighty <- letters2[-indexTrainEighty, ]


knnFitEighty<- train(letter ~., data = trainSetEighty, method ='knn' , tuneGrid = data.frame( k = c(141)))

EightyknnPredict<- predict(knnFitEighty, newdata = testSetEighty)


confusionMatrix(EightyknnPredict, as.factor(testSetEighty$letter))


```

```{r, eval = FALSE}
#Most Accurate k

set.seed(6)

indexTrainMax<- createDataPartition(letters2$xPos, times =1,  p = 0.70, list = FALSE)

trainSetMax <- letters2[indexTrainMax, ]
#define test set as complement of the test set
testSetMax <- letters2[-indexTrainMax, ]

knnfitMax<- train(letter ~., data = trainSetMax, method ='knn' , tuneGrid = data.frame( k = c(seq(101, 201, 2))))

#best k was 101 at 78% for 101 to 201

str(knnfitMax)
knnMaxpredict<- predict(knnfitMax, newdata = testSetMax)

confusionMatrix(knnMaxpredict, as.factor(testSetMax$letter) )


knnfitMax$results
```

```{r}
#Analyze Smaller values of K
set.seed(6)

indexTrain2<- createDataPartition(letters2$xPos, times =1,  p = 0.70, list = FALSE)
testSet2<- letters2[-indexTrain2, ]
trainSet2<- letters2[indexTrain2, ]

knnfit2<- train(letter ~., data = trainSet2, method ='knn' , tuneLength = 5)
                #tuneGrid = expand.grid(k = 1:10))
                  #data.frame( k = c(seq(1, 99, 2))))

knnpredict2<- predict(knnfit2, newdata = testSet2)
confusionMatrix(knnpredict2, as.factor(testSet2$letter) )

```

