---
title: "FinalProject KNN Algorithm"
author: "Grant Burden"
date: "2023-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Final Project for INFO 523

```{r}
'P. W. Frey and D. J. Slate (Machine Learning Vol 6 #2 March 91):
	"Letter Recognition Using Holland-style Adaptive Classifiers".'

```

```{r, echo = FALSE, results = 'hide'}
library(caret)
library(tidyverse)

```

```{r}
#Load the UCi dataset
letters1<- read.csv('./letter-recognition.data', header = FALSE)

#names is citation info--not needed for algorithm
#names1 <- read.csv('./letter-recognition.names', header = FALSE)

head(letters1)

#we have 16 predictors for 26 classes, and 20k observations total
str(letters1)
names(letters1)

#Renaame Column Headers

letters2 <- letters1%>%rename(
 letter  = V1,
  xPos = V2,
  yPos = V3,
  pixWidth = V4,
   pixHeight= V5,
  pixOn = V6,
  xMean = V7,
   yMean= V8,
  xMeanSq = V9,
   yMeanSq= V10,
   XYMean= V11,
  xCorY = V12,
  YCorX = V13,
  edgeMeanHoriz = V14,
   edgeYSum= V15,
   edgeMeanY= V16,
   edgeXSum= V17
   
) 


```
Split into test and Traning sets
Trying a 70/30 train test split
set seed for the same splits

```{r}
#split into training and test
#Get indices of rows in training set, 70% of rows of letters1, 
#set seed keep split consistent

set.seed(6)
indexTrain<- createDataPartition(letters2$xPos, times =1,  p = 0.70, list = FALSE)

#define training set
trainSet <- letters2[indexTrain, ]
#define test set as complement of the test set
testSet <- letters2[-indexTrain, ]


```
Try different values for K--find optimal accuracy and plot it
sqrt(n) ~ 140

```{r}
knnFit<- train(letter ~., data = trainSet, method ='knn' , tuneGrid = data.frame( k = c(141)))

#multiKnnFit<- knnFit<- train(letter ~., data = trainSet, method ='knn' , tuneGrid = data.frame( k = seq(141, 200,2)))

#view results of knnFit model
knnFit$results

knnTestPredict<- predict(knnFit, newdata = testSet )


class(knnTestPredict)
#how accurate did knn predict the letters on the test set
confMatrixKnn<- confusionMatrix(knnTestPredict, as.factor(testSet$letter))

confMatrixKnn$byClass[,1]

```

Crossfold validation maybe?
knn3 algo

```{r}
#make the results into a df
cm_df<- as.data.frame(confMatrixKnn$byClass)

cm_df
#add column with Letter Classes
letter_col<- LETTERS[seq(from = 1 , to = 26)]
letters_df<- cm_df%>%mutate(Letter_Class = letter_col)

plot_balanced_acc<- letters_df%>%ggplot(aes(x = Letter_Class, y = `Balanced Accuracy` ))+
  geom_point(col = 'darkblue')+
  ggtitle('Balanced Accuracy for Letter Predictions via KNN')+
  xlab('Letter Class')

plot_specificity <- letters_df%>%ggplot(aes(x = Letter_Class, y = Specificity ))+
  geom_point(col = 'darkgreen')+
  ggtitle('Specificity for Letter Predictions via KNN')+
  xlab('Letter Class')


plot_sensitivity <- letters_df%>%ggplot(aes(x = Letter_Class, y = Sensitivity))+
  geom_point(col = 'maroon4')+
  ggtitle('Sensitivityfor Letter Predictions via KNN')+
  xlab('Letter Class')
```

