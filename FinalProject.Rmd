---
title: "FinalProject KNN Algorithm"
author: "Grant Burden"
date: "2023-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Final Project for INFO 523

```{r}
'P. W. Frey and D. J. Slate (Machine Learning Vol 6 #2 March 91):
	"Letter Recognition Using Holland-style Adaptive Classifiers".'

```

```{r, echo = FALSE, results = 'hide'}
library(caret)
library(tidyverse)

```

```{r}
#Load the UCi dataset
letters1<- read.csv('./letter-recognition.data', header = FALSE)

#names is citation info--not needed for algorithm
#names1 <- read.csv('./letter-recognition.names', header = FALSE)

head(letters1)

#we have 16 predictors for 26 classes, and 20k observations total
str(letters1)
names(letters1)

#Reaname Column Headers

letters2 <- letters1%>%rename(
 letter  = V1,
  xPos = V2,
  yPos = V3,
  pixWidth = V4,
   pixHeight= V5,
  pixOn = V6,
  xMean = V7,
   yMean= V8,
  xMeanSq = V9,
   yMeanSq= V10,
   XYMean= V11,
  xCorY = V12,
  YCorX = V13,
  edgeMeanHoriz = V14,
   edgeYSum= V15,
   edgeMeanY= V16,
   edgeXSum= V17
   
) 
```
Split into test and Traning sets
Trying a 70/30 train test split
set seed for the same splits

```{r}
set.seed(4)
#indexTrain<- createDataPartition(y = df, times, p = traningdata propostion)
'trainSet <- df[indexTrain, ]'
'testSet <- df[-indexTrain]'
```
Try different values for K--find optimal accuracy and plot it
sqrt(n) ~ 140

```{r}
'knnfit<- train(df, method = , tuneGrid = )'
'knnpredict<- predict(knnfit, newdata = )'
```

Crossfold validation maybe?

