---
title: "FinalProject KNN Algorithm"
author: "Grant Burden"
date: "2023-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Final Project for INFO 523

```{r}
'P. W. Frey and D. J. Slate (Machine Learning Vol 6 #2 March 91):
	"Letter Recognition Using Holland-style Adaptive Classifiers".'

```

```{r, echo = FALSE, results = 'hide'}
library(caret)
library(tidyverse)

```

```{r}
#Load the UCi dataset
letters1<- read.csv('./letter-recognition.data', header = FALSE)

#names is citation info--not needed for algorithm
#names1 <- read.csv('./letter-recognition.names', header = FALSE)

head(letters1)

#we have 16 predictors for 26 classes, and 20k observations total
str(letters1)
names(letters1)

#Renaame Column Headers

letters2 <- letters1%>%rename(
 letter  = V1,
  xPos = V2,
  yPos = V3,
  pixWidth = V4,
   pixHeight= V5,
  pixOn = V6,
  xMean = V7,
   yMean= V8,
  xMeanSq = V9,
   yMeanSq= V10,
   XYMean= V11,
  xCorY = V12,
  YCorX = V13,
  edgeMeanHoriz = V14,
   edgeYSum= V15,
   edgeMeanY= V16,
   edgeXSum= V17
   
) 


```
Split into test and Traning sets
Trying a 70/30 train test split
set seed for the same splits

```{r}
#split into training and test
#Get indices of rows in training set, 70% of rows of letters1, 
#set seed keep split consistent

set.seed(6)
indexTrain<- createDataPartition(letters2$xPos, times =1,  p = 0.70, list = FALSE)

#define training set
trainSet <- letters2[indexTrain, ]
#define test set as complement of the test set
testSet <- letters2[-indexTrain]


```
Try different values for K--find optimal accuracy and plot it
sqrt(n) ~ 140

```{r}
#knnFit<- train(trainSet, method ='knn' , tuneGrid = )
#knnpredict<- predict(knnfit, newdata = )
```

Crossfold validation maybe?

